{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "翻译：将德语翻译成英语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step = 5\n",
    "n_hidden = 128\n",
    "\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "# S 代表 input的解码开始的标志\n",
    "# E 代表 output的解码开始的标志\n",
    "# 错开一位表示，output的解码用到了output的前一位的内容\n",
    "\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w:i for i,w in enumerate(word_list)}\n",
    "number_dict = {i:w for i,w in enumerate(word_list)}\n",
    "n_class = len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "\n",
    "    # make tensor\n",
    "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
    "input_batch, output_batch, target_batch = make_batch()\n",
    "# input_batch (1,5,11)\n",
    "# output_batch (1,5,11)\n",
    "# target_batch (1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
    "\n",
    "        # Linear for attention\n",
    "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
    "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
    "\n",
    "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
    "        enc_inputs = enc_inputs.transpose(0, 1)  # enc_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        # enc_inputs (1,5,11) -> (5,1,11) \n",
    "        dec_inputs = dec_inputs.transpose(0, 1)  # dec_inputs: [n_step(=n_step, time step), batch_size, n_class]\n",
    "        # dec_inputs (1,5,11) -> (5,1,11)\n",
    "        # hidden (1,1,128)\n",
    "\n",
    "        # enc_outputs : [n_step, batch_size, num_directions(=1) * n_hidden], matrix F  (5,1,128)\n",
    "        # enc_hidden : [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
    "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
    "        # 编码过程\n",
    "\n",
    "        trained_attn = []\n",
    "        hidden = enc_hidden\n",
    "        n_step = len(dec_inputs)\n",
    "        model = torch.empty([n_step, 1, n_class])\n",
    "\n",
    "        for i in range(n_step):  # each time step\n",
    "            # dec_output : [n_step(=1), batch_size(=1), num_directions(=1) * n_hidden]  (1,1,128)\n",
    "            # hidden : [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
    "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)  \n",
    "            attn_weights = self.get_att_weight(dec_output, enc_outputs)  # attn_weights : [1, 1, n_step]\n",
    "            trained_attn.append(attn_weights.squeeze().data.numpy())\n",
    "\n",
    "            # matrix-matrix product of matrices [1,1,n_step] x [1,n_step,n_hidden] = [1,1,n_hidden]\n",
    "            context = attn_weights.bmm(enc_outputs.transpose(0, 1))  # (1,1,128) \n",
    "            # context的维度解释： 这里的第一个1指的是batch_size，第二个1指得是 上下文的step的注意力结果\n",
    "            \n",
    "            dec_output = dec_output.squeeze(0)  # dec_output : [batch_size(=1), num_directions(=1) * n_hidden]\n",
    "            # dec_output (1,128) context (1,128)\n",
    "            context = context.squeeze(1)  # [1, num_directions(=1) * n_hidden]\n",
    "            model[i] = self.out(torch.cat((dec_output, context), 1))  # (1,256) -> (1, 11)\n",
    "\n",
    "        # make model shape [n_step, n_class]\n",
    "        return model.transpose(0, 1).squeeze(0), trained_attn  # (5,11), (5,5)\n",
    "    \n",
    "    \n",
    "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
    "        # dec_output (1,1,128)   这里是指 输出序列的前一位经过rnn的隐藏层结果\n",
    "        # enc_outputs (5,1,128)  这里是指 输入序列经过rnn的隐藏层结果\n",
    "        n_step = len(enc_outputs)  # 5\n",
    "        attn_scores = torch.zeros(n_step)  # attn_scores : [n_step]\n",
    "\n",
    "        for i in range(n_step):\n",
    "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
    "\n",
    "        # Normalize scores to weights in range 0 to 1\n",
    "        return F.softmax(attn_scores).view(1, 1, -1)  #  (1,1,5)\n",
    "\n",
    "    def get_att_score(self, dec_output, enc_output):  # enc_outputs [batch_size, num_directions(=1) * n_hidden]\n",
    "        score = self.attn(enc_output)  # score : [batch_size, n_hidden]\n",
    "        return torch.dot(dec_output.view(-1), score.view(-1))  # inner product make scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "hidden = torch.zeros(1, 1, n_hidden)\n",
    "\n",
    "model = Attention()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000482\n",
      "Epoch: 0800 cost = 0.000154\n",
      "Epoch: 1200 cost = 0.000075\n",
      "Epoch: 1600 cost = 0.000044\n",
      "Epoch: 2000 cost = 0.000028\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_batch, hidden, output_batch)\n",
    "\n",
    "    loss = criterion(output, target_batch.squeeze(0))\n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.5311, -2.8637, -2.7157, -2.6841,  1.2780, -2.8028,  0.9134, -0.1137,\n",
      "         -2.4337, -1.0854, -2.2895],\n",
      "        [ 1.5402, -3.1265, -3.5508, -4.3131, 12.6553, -3.5405,  1.2448,  0.4846,\n",
      "         -3.4005,  0.0499, -2.9443],\n",
      "        [ 1.5803, -3.6186, -4.2921, -3.5869,  1.5879, -3.7818, 12.9197,  0.8593,\n",
      "         -2.9404, -1.2776, -3.4864],\n",
      "        [-1.1015, -3.0317, -2.9598, -2.8530, -0.5667, -2.9552, -1.4771, -0.4128,\n",
      "         -2.7779, 10.9956, -2.7380],\n",
      "        [ 0.9079, -3.0049, -2.7077, -2.6040,  0.5338, -2.9172,  0.7914, 12.7296,\n",
      "         -2.7146,  0.8651, -2.4170]], grad_fn=<SqueezeBackward1>)\n",
      "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SSSSS']]]\n",
    "test_batch = torch.FloatTensor(test_batch)\n",
    "predict, trained_attn = model(input_batch, hidden, test_batch)\n",
    "print(predict)\n",
    "predict = predict.data.max(1, keepdim=True)[1]\n",
    "print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show Attention\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.matshow(trained_attn, cmap='viridis')\n",
    "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
